# AI Large Language Model Conversational Format Resume (LLM Conversation Resume, LLMCR)

利用「人工智慧大型語言模型對話」履歷(LLMCR)取代傳統的學經歷的履歷表，應徵任務的夥伴須先依據任務要求提供LLMCR，LLMCR是一種使用AI對話呈現執行任務的履歷證明，這是一種未來的履歷形式之一，可讓應徵任務者藉由與具備前沿能力的大型語言模型對話來展示其具備足以完成任務的能力。

駕馭未來：AI時代求職成功的兩大新關鍵

隨著 AI 崛起，傳統衡量成功的標準，如名校背景或輝煌經歷，重要性已不如以往。科技界名人 Garry Tan 指出，未來職場更看重與 AI 互動的兩種核心能力。首先是主導力 (Agency)，也就是你的提示力 (Prompting)。這代表你能否主動且清晰地指揮 AI，就像駕駛員駕馭引擎，透過精確的指令引導 AI 達成特定目標、解決問題。這考驗的是你運用工具、主動出擊的能力。其次是品味 (Taste)，即 鑑賞力 (Evaluation)。當 AI 產出結果後，你需要有能力判斷其好壞。這需要批判性思考，辨別 AI 成品是真正高品質、具創意且正確，還是僅僅看似合格。如同美食家品評料理，你要能評估 AI 的優劣，並指導其改進。

這兩種能力相輔相成，缺一不可。僅有主導力而無品味，會被平庸或錯誤的 AI 產出淹沒；空有品味卻無主導力，則無法有效創造價值。Garry Tan 認為，同時掌握這兩者，才能將 AI 這個強大工具變為成功的加速器。因此，未來履歷表脫穎而出的關鍵，已從你的背景轉變為：你是否能成為一位既懂得指揮 AI、又懂得鑑賞其成果的「AI 合作大師」。

下面我們將利用舉例來說明我們期望 LLMCR 至少具備兩個部份內容，一個是任務說明的閱讀理解情境，一個是面試情境。利用對話讓應徵者證明其接受任務的能力，不限制語言模型，建議使用較好的模型來面試，缺少這兩種情境的 LLMCR 將被視為無法勝任任務。

LLMCR 須提供可線上閱讀URL連結，目前免費層級推薦用 Google AI Studio 語言模型，當然也可以使用 ChatGPT或其它可提供線上閱覽對話過程之大型語言模型服務商，只要這些服務商能提供讓雇主能夠使用瀏覽器點擊連結來閱讀應徵者的 LLMCR 即可。

下面用數位憑證皮夾沙盒測試為範例來說明一個AI履歷要如何完成。

## LLMCR必備內容：任務說明的閱讀理解情境

LLMCR 對話中必須有對任務說明的閱讀理解，必須依據指示提交相關文件給AI請其摘要與對話講解其內容。

例如數位憑證皮夾沙盒測試任務須惰下列文件進行閱讀與理解：

數位發展部「分散式驗證及授權系統建置案」沙盒系統操作手冊-發行端
https://issuer-sandbox.wallet.gov.tw/operation-manual.pdf

數位發展部「分散式驗證及授權系統建置案」沙盒系統操作手冊-驗證端
https://verifier-sandbox.wallet.gov.tw/operation-manual.pdf

對於任務手冊有不清楚的地方直接問到確認已經理解。請特別注意這些對話必須將之視為其任務履歷的一部分，後續將用來呈現給雇主觀察其能力，建議應徵者在提問與對話中強化主導力 (Agency)與品味 (Taste)。

## LLMCR必備內容：面試情境

LLMCR 對話中必須有面試情境，利用LLM來扮演面試者角色，確認應徵者確實具備執行任務的能力，可以參考範例對話如下：

> 你是一個資深的資訊科技公司技術人力資源主管，具備豐富的技術經驗同時負責面試應徵者，你要主導進行一次面試，評估任務應徵者是否具備足夠的知識或技能來完成任務：
> 
> 步驟如下：
> 
> 1.首先必須對應徵者說明上述兩個沙盒系統操作手冊主要內容，確認應徵者理解並具備操作手冊所需的執行任務能力，再進行後續面試流程。
> 
> 2.完成步驟1之後根據數位發展部沙盒系統操作手冊的來產生10個面試問題，確認應徵者已經具備任務所需的操作能力。1面試問題順序為5個四選一的選擇題與2個問答題，每個選擇題問題應包含一個正確選項（直接來自操作手冊）和三個看似合理但不正確的干擾選項。如果使用者答對全部選擇題目，則進入問答題。若有答錯選擇題，請針對錯誤的題目再次解釋相關操作內容，然後重新提問（或換題目提問），直到應徵者全部答對為止再進入問答題。
> 
> 3.根據面試題目的回應直接提供評分給應徵者並給予適當建議，你針對每個面試問題的回應，從以下幾個核心維度進行評分，每個維度給予0-3分：
>
> 技術正確性與完整性 (Technical Accuracy & Completeness)，評估重點: 回答內容的技術細節是否正確？是否涵蓋了問題的核心要點？有沒有遺漏關鍵資訊？
0分: 完全錯誤、答非所問或未回答。1分: 部分正確，但有明顯錯誤或嚴重遺漏關鍵概念。2分: 大致正確，涵蓋主要概念，但可能缺乏細節或有輕微錯誤/不精確之處。3分: 完全正確，資訊完整且精確，涵蓋所有重要方面。
> 
> 理解深度與廣度 (Depth & Breadth of Understanding)，評估重點: 應徵者是否不僅知道「是什麼」，還知道「為什麼」？能否解釋概念背後的原理、優缺點、適用場景或與其他技術的關聯？
0分: 完全不理解，僅是死記硬背或完全無法解釋。1分: 表面理解，能說出基本定義，但無法深入解釋或闡述。2分: 理解良好，能解釋基本原理和部分應用場景，但可能缺乏對複雜情況或替代方案的考量。3分: 理解深入且有廣度，能清晰解釋原理、權衡利弊、說明不同情境下的應用，甚至能觸類旁通。
> 
> 表達清晰度與邏輯結構 (Clarity & Structure)，評估重點: 回答是否條理分明、易於理解？用詞是否精確？邏輯是否清晰連貫？
0分: 表達混亂、語無倫次、難以理解。1分: 表達不清，結構鬆散，需要費力才能理解其意圖。2分: 大致清晰，能聽懂主要意思，但結構或用詞可以更精進。3分: 表達非常清晰，結構嚴謹，邏輯性強，用詞精確易懂。


請特別注意上述這些情境對話包含LLM角色設定等都是 LLMCM 任務履歷的一部分，LLMCM 用來呈現給雇主觀察其在主導力 (Agency)與品味 (Taste)方面的能力。

## Google AI Studio 線上連結範例

需要 Google AI Studio 帳號才能查看。這並不是上述的數位憑證皮夾沙盒測試任務範例，只是供一個可供閱覽的對話連結供參考。

討論AI時代求職履歷成功的兩大新關鍵對話：

https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221X3gclDNWbOReK2Btz7UaigDEvaqoZJID%22%5D,%22action%22:%22open%22,%22userId%22:%22116052379623397587610%22,%22resourceKeys%22:%7B%7D%7D&usp=sharing


